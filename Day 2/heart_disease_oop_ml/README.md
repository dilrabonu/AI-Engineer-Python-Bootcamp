# Day 2 â€“ OOP Machine Learning Pipeline (Heart Disease Prediction)

A modular, scalable, production-grade ML architecture built using Python OOP

*ğŸš€ Project Overview*

Day 2 focuses on building a fully modular, object-oriented machine learning system â€” the same engineering style used at Google, Amazon, Meta, Netflix, and Apple.

We refactor a classical ML workflow into clean, testable, reusable components:

Dataset Loader

Tabular Preprocessor

Model Wrapper (Logistic Regression / Random Forest)

Training Orchestrator

Configuration System (dataclasses)

Logging for debugging and production readiness

This creates an industry-grade ML pipeline that can easily scale to new datasets, models, and deployment systems.

ğŸ§  Problem Statement

We use the Heart Disease Cleveland Dataset to predict whether a patient is likely to have heart disease.

Input: 13 medical features (age, sex, cp, chol, trestbps, thalach, etc.)

Output: condition â†’ 1 (disease), 0 (no disease)

Task Type: Binary Classification

Algorithms: Logistic Regression / Random Forest

ğŸ—ï¸ Project Architecture (FAANG-style)

heart_disease_oop_ml/
â”‚
â”œâ”€â”€ data/

â”‚   â””â”€â”€ heart_cleveland_upload.csv

â”‚

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ data/

â”‚   â”‚   â””â”€â”€ dataset_loader.py

â”‚   â”‚

â”‚   â”œâ”€â”€ preprocessing/

â”‚   â”‚   â””â”€â”€ preprocessor.py

â”‚   â”‚

â”‚   â”œâ”€â”€ models/

â”‚   â”‚   â””â”€â”€ model_wrapper.py

â”‚   â”‚

â”‚   â”œâ”€â”€ training/

â”‚   â”‚   â””â”€â”€ trainer.py

â”‚   â”‚

â”‚   â””â”€â”€ utils/

â”‚       â”œâ”€â”€ config.py


â”‚       â””â”€â”€ logging_utils.py

â”‚

â”œâ”€â”€ main.py

â”œâ”€â”€ README.md

â””â”€â”€ requirements.txt

This structure separates responsibilities clearly â€” a key requirement for scalable ML systems.

**ğŸ§© Main Components**
ğŸ”¹ 1. DataConfig, ModelConfig, TrainingConfig

Defined using Python dataclasses, enabling:

Reproducibility

Clear configuration

No hardcoded values

Easy switching of models / parameters

ğŸ”¹ 2. DatasetLoader

Handles:

Reading CSV

Splitting into train/test

Extracting target column

Returning numpy arrays

ğŸ”¹ 3. TabularPreprocessor

StandardScaler applied with fit only on training data â†’ prevents data leakage.

ğŸ”¹ 4. ModelWrapper

Wraps ML models behind a unified interface:

.fit()

.predict()

.predict_proba()

.evaluate()

Supports:

Logistic Regression

Random Forest

Adding new models becomes trivial.

ğŸ”¹ 5. Trainer

Orchestrates the entire ML lifecycle:

Load data

Preprocess

Train model

Evaluate

Log results

ğŸ“Š Model Performance

Using Logistic Regression:

Metric	Score
Accuracy	0.9166
ROC-AUC	0.9531

A high ROC-AUC indicates excellent medical prediction performance.

â–¶ï¸ How to Run
python main.py


All configuration is handled in:

src/utils/config.py

ğŸ§ª Next Extensions (Recommended)

SHAP explainability

Feature importance visualization

Add XGBoost / LightGBM models

Build API using FastAPI

Unit tests for the pipeline

Hyperparameter tuner module

ğŸ… Skills Demonstrated

Professional ML Engineering

Object-Oriented Design

Clean Architecture

Config-Driven Development

Logging & Reproducibility

Production-ready pipelines

ğŸ“¦ Dependencies

Install required packages:

pip install -r requirements.txt

â­ Summary

Day 2 delivers a real machine learning system, not just a notebook.
You built something that mirrors FAANG-level ML engineering practices:

Modular

Scalable

Testable

Reusable

Clean OOP design

This is exactly the kind of structure companies want.
